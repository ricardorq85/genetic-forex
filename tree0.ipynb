{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tree0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardorq85/genetic-forex/blob/master/tree0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJuO5bu5xloy",
        "colab_type": "text"
      },
      "source": [
        "# Árboles de decisión\n",
        "\n",
        "En este cuaderno vamos a implementar árboles de decisión para un problema de clasificación binaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmweCCoOxYO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from sklearn.datasets import make_moons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMRJx8OOzY_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rc('font', family='serif')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HihSRIDLzXYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_decision_regions(X, y, classifier=None, resolution=0.02):\n",
        "    \"\"\" Taken from Rashka's book \"\"\"\n",
        "    # setup marker generator and color map\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "    \n",
        "    # plot the decision surface\n",
        "    x1_min, x1_max = X[:, 0].min() - 0.3, X[:, 0].max() + 0.3\n",
        "    x2_min, x2_max = X[:, 1].min() - 0.3, X[:, 1].max() + 0.3\n",
        "    xx1, xx2 = np.meshgrid(\n",
        "        np.arange(x1_min, x1_max, resolution),\n",
        "        np.arange(x2_min, x2_max, resolution)\n",
        "    )\n",
        "    \n",
        "    if classifier is not None:\n",
        "        Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "        Z = Z.reshape(xx1.shape)\n",
        "        plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
        "        \n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "    \n",
        "    # plot class samples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(\n",
        "            x=X[y == cl, 0],\n",
        "            y=X[y == cl, 1],\n",
        "            alpha=0.8,\n",
        "            c=colors[idx],\n",
        "            marker=markers[idx],\n",
        "            label=cl,\n",
        "            edgecolor='black'\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LC2COK2zYLV",
        "colab_type": "code",
        "outputId": "9e315893-f01b-4e54-a6d1-0bbb860df8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "X, y = make_moons(noise=0.2)\n",
        "plot_decision_regions(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD7CAYAAABjVUMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvxttQMFHypa",
        "colab_type": "text"
      },
      "source": [
        "Primero vamos a definir una clase llamada Dataset, la cual contiene un atributo `features` y un atributo `labels`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJPYkvSQPTro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, features, labels):\n",
        "        \n",
        "        #The following assertion should be uncomented,\n",
        "        #but it is easier to verify your without it.\n",
        "        #assert features.shape[0] == labels.shape[0]\n",
        "        \n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.length = labels.shape[0]\n",
        "        \n",
        "#    def __getitem__(self, i):\n",
        "#        features = self.features[i,:]\n",
        "#        labels = self.labels[i]\n",
        "#        return type(self)(features, labels)\n",
        "        \n",
        "    def __repr__(self):\n",
        "        msg = \"Dataset my dataset of {} observations and {} predictor variables\"\n",
        "        return msg.format(self.length, self.features.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj5Wb59Za5Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.array([0,0,1,1,1,2,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCvJgHSZbCw7",
        "colab_type": "code",
        "outputId": "497739c6-8f24-451f-88dc-648ee26c6c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(labels == 0).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nICD_nxZVaA1",
        "colab_type": "text"
      },
      "source": [
        "## Componentes de un árbol de decisión\n",
        "**Ejercicio 1:** calcular la proporción de elementos de un conjunto de datos que pertenece a una clase en particular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktmZbPJkVZWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _proportion(c, ds):\n",
        "    \"\"\" compute the proportion of data points of class c in dataset ds. \"\"\"\n",
        "    # your code starts here\n",
        "    num = (ds.labels == c).sum()\n",
        "    den = ds.length\n",
        "    prop = num/den\n",
        "    # your code ends here\n",
        "    return prop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3NwuQ2zXQeZ",
        "colab_type": "text"
      },
      "source": [
        "Si todo funciona, el resultado de la siguiente celda debe ser 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TgshkFWVgJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = Dataset(features=None, labels=np.array([0, 0, 1, 0]))\n",
        "print(\"Proportion of class {} is {}\".format(1, _proportion(1, ds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1fQoT-QXYGH",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 2:** crear una función que compute el indice gini de un conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUHjUPXSVgDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _gini_index(ds):\n",
        "    \"\"\" Computes the gini index of ds \"\"\"\n",
        "    # your code starts here\n",
        "    \n",
        "    # your code ends here\n",
        "    return gini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WLT32QuZyFy",
        "colab_type": "text"
      },
      "source": [
        "Si lo hiciste bien, lo siguiente debe resultar en 0.375"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FmqJ7RsVf1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = Dataset(features=None, labels=np.array([0, 0, 1, 0]))\n",
        "print(\"The Gini index of the data set is {}\".format(_gini_index(ds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFsCsRohaII9",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 3:** implementar una función que calcule la entropía en un conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfCAjxIbaPdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _entropy(ds):\n",
        "    \"\"\" Computes the entropy of a data set\"\"\"\n",
        "    # here starts your code\n",
        "    \n",
        "    props = \n",
        "    # here ends your code\n",
        "    return entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRgstvz0cIpA",
        "colab_type": "text"
      },
      "source": [
        "Lo siguiente debe dar 0.81"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ron86HI0bdRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = Dataset(features=None, labels=np.array([0, 0, 1, 0]))\n",
        "print(\"The Entropy of the data set is {:.2f}\".format(_entropy(ds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elKz6BYQdcAk",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 4:** implementar la función para calcular la ganancia de información"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbXUvssDbc-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _info_gain(ds, ds_left, ds_right, impurity_fn):\n",
        "    \"\"\"Compute the information gain of a split.\"\"\"\n",
        "    # here starts your code\n",
        "    \n",
        "    info_gain = \n",
        "    # here ends your code\n",
        "    return info_gain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4q80EQsObY",
        "colab_type": "text"
      },
      "source": [
        "Lo siguiente debe dar 0.12 y 0.19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YV_P-tfm4UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = Dataset(features=None, labels=np.array([0, 0, 0, 0, 1, 1, 1, 1]))\n",
        "ds_left = Dataset(features=None, labels=np.array([0, 0, 0, 1]))\n",
        "ds_right = Dataset(features=None, labels=np.array([0, 1, 1, 1]))\n",
        "\n",
        "msg = \"The information gain of the split using gini index is {:.2f}\"\n",
        "print(msg.format(_info_gain(ds, ds_left, ds_right, _gini_index)))\n",
        "\n",
        "msg = \"The information gain of the split using entropy is {:.2f}\"\n",
        "print(msg.format(_info_gain(ds, ds_left, ds_right, _entropy)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNntDkB5vKae",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 5:** implemente la función que parte un conjunto de datos en 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLWpVaJZm4MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _split_ds(ds, idx, value):\n",
        "    \"\"\" Create left and right splits of ds based on idx and value\"\"\"\n",
        "    #here starts your code\n",
        "    \n",
        "    \n",
        "    # here ends your code\n",
        "    return ds_left, ds_right"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nei-CFyfwzyP",
        "colab_type": "text"
      },
      "source": [
        "We are expecting the following result: \n",
        "\n",
        "\n",
        "```\n",
        "Left...features: [[1.9 1.3]\n",
        " [2.7 1.1]]. labels [0 0].\n",
        "Right...features: [[9.5 3.6]\n",
        " [7.2 3.1]\n",
        " [7.4 0.3]]. labels [1 1 1].\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWumsfjPm36a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ = np.array([[1.9,1.3],\n",
        "\t           [2.7,1.1],\n",
        "               [9.5,3.6],\n",
        "               [7.2,3.1],\n",
        "               [7.4,0.3]])\n",
        "y_ = np.array([0,0,1,1,1])\n",
        "ds = Dataset(X_, y_)\n",
        "ds_left, ds_right = _split_ds(ds, 0, 5)\n",
        "\n",
        "msg = \"Left...features: {}. labels {}.\"\n",
        "print(msg.format(ds_left.features, ds_left.labels))\n",
        "\n",
        "msg = \"Right...features: {}. labels {}.\"\n",
        "print(msg.format(ds_right.features, ds_right.labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGdviHam5-Pq",
        "colab_type": "text"
      },
      "source": [
        "**Ejercicio 6:** implementa una función que encuentre el mejor punto (índice y valor) para dividir un conjunto de datos. El resultado de esta función debe ser un diccionario que contenga los campos `idx, value, ds_left, ds_right`. La implementación está casi lista, solo debes reemplazar cosas que hacen que no funcione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7BgU9Gk3Pt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _best_split(ds, impurity_fn):\n",
        "    \"\"\" find the best split of a dataset using the given impurity_fn\"\"\"\n",
        "    #set best value to the lowest possible\n",
        "    best = \n",
        "    \n",
        "    indices = ds.features.shape[1]\n",
        "    \n",
        "    for idx in range(indices):\n",
        "        for _ in _:\n",
        "            ds_left, ds_right = ####\n",
        "            temp = #####\n",
        "            if ####:\n",
        "                best = temp\n",
        "                result = {\n",
        "                    'idx': idx, \n",
        "                    'value': value,\n",
        "                    'ds_left': ds_left,\n",
        "                    'ds_right': ds_right\n",
        "                }\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbQjc-RM-FTI",
        "colab_type": "text"
      },
      "source": [
        "El mejor punto debe ser en el índice 0 y con el valor 3.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAcOUxuo3PRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ = np.array([[1.9,1.3],\n",
        "\t           [2.7,1.1],\n",
        "               [3.3,2.1],\n",
        "               [3.6,2.9],\n",
        "               [0.8,2.4],\n",
        "               [9.5,3.6],\n",
        "               [7.2,3.1],\n",
        "               [7.4,4.3],\n",
        "               [10.1,3.5],\n",
        "               [6.2,3.7]])\n",
        "y_ = np.array([0,0,0,0,0,1,1,1,1,1])\n",
        "ds = Dataset(X_, y_)\n",
        "result = _best_split(ds, _gini_index)\n",
        "msg = \"The best split ocurs at index {} and value {}\"\n",
        "print(msg.format(result['idx'], result['value']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9r9-_ne2ED9",
        "colab_type": "text"
      },
      "source": [
        "## Árbol de decisión en una clase\n",
        "Ya tenemos casi todo lo necesario para implementar una clase que se encargue de todo. Una de las ventajas de poner todo en una clase, es que esta se puede reutilizar más fácilmente; esto puede implicar que le podemos poner una interfaz a nuestro modelo que se adapte bien a como todo funciona dentro de la empresa. \n",
        "\n",
        "Falta muy poco para terminar de implementar nuestro árbol de decisión para clasificación. Lo que falta no será ejercicio sino que se dará como ejemplo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khfuCmA3jUfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=5, criterion='gini'):\n",
        "        self._root = None\n",
        "        self.max_depth = max_depth\n",
        "        if criterion == 'gini':\n",
        "            self._impurity_fn = lambda x: _gini_index(x)\n",
        "        else:\n",
        "            self._impurity_fn = lambda x: _entropy(x)\n",
        "               \n",
        "    \n",
        "    def _best_split(self, ds):\n",
        "        return _best_split(ds, self._impurity_fn)\n",
        "    \n",
        "    def _define_class(self, labels):\n",
        "        return np.bincount(labels).argmax()\n",
        "    \n",
        "    def _recursive_split(self, node, depth):\n",
        "        \n",
        "        ds_left, ds_right = node['ds_left'], node['ds_right']\n",
        "        del node['ds_left']; del node['ds_right']\n",
        "        \n",
        "        if ds_left.length == 0 or ds_right.length == 0:\n",
        "            all_labels = np.concatenate((ds_left.labels, ds_right.labels))\n",
        "            val = self._define_class(all_labels)\n",
        "            node['left'] = node['right'] = val\n",
        "            return\n",
        "            \n",
        "        if depth >= self.max_depth:\n",
        "            node['left'] = self._define_class(ds_left.labels)\n",
        "            node['right'] = self._define_class(ds_right.labels)\n",
        "            return \n",
        "           \n",
        "        if  ds_left.length == 1:\n",
        "            node['left'] = self._define_class(ds_left.labels)\n",
        "        else:\n",
        "            node['left'] = self._best_split(ds_left)\n",
        "            self._recursive_split(node['left'], depth + 1)\n",
        "            \n",
        "        if ds_right.length == 1:\n",
        "            node['right'] = self._define_class(ds_right.labels)\n",
        "        else:\n",
        "            node['right'] = self._best_split(ds_right)\n",
        "            self._recursive_split(node['right'], depth + 1)\n",
        "      \n",
        "    def fit(self, X, y):\n",
        "        self._root = self._best_split(Dataset(X, y))\n",
        "        self._recursive_split(self._root, 1)\n",
        "        \n",
        "    def _recursive_travel(self, node, x):\n",
        "        idx = node['idx']\n",
        "        value = node['value']\n",
        "        if x[idx] <= value:\n",
        "            if isinstance(node['left'], dict):\n",
        "                return self._recursive_travel(node['left'], x)\n",
        "            else:\n",
        "                return node['left']\n",
        "        else:\n",
        "            if isinstance(node['right'], dict):\n",
        "                return self._recursive_travel(node['right'], x)\n",
        "            else:\n",
        "                return node['right']\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self._root is not None:\n",
        "            iterable = (self._recursive_travel(self._root, xi) for xi in X)\n",
        "            return np.fromiter(iterable, int, X.shape[0])\n",
        "        else:\n",
        "            raise RuntimeError(\"please train me first\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3GE7FIRuoj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mytree = DecisionTreeClassifier(max_depth=5, criterion='entropy')\n",
        "mytree.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9XHqUGPwpf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(mytree.predict(X) == y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM0DGve4mNUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_decision_regions(X, y, classifier=mytree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyjWcBnJMMUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}